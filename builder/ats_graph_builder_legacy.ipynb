{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "PROJECT_ROOT = os.getenv('PROJECT_ROOT')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "def is_in_europe(lat, lon):\n",
    "    \"\"\"\n",
    "    Checks if a given latitude and longitude fall within an approximate bounding\n",
    "    box for the European continent.\n",
    "    \n",
    "    Europe is approximated as:\n",
    "      Latitude: 30°N to 72°N\n",
    "      Longitude: -25°E to 45°E\n",
    "    \"\"\"\n",
    "    return 30 <= lat <= 72 and -25 <= lon <= 45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def generate_random_two_digits():\n",
    "    return str(random.randint(0, 99)).zfill(2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph_from_ats(filename, bidirectional=False):\n",
    "    \"\"\"\n",
    "    Builds a graph from an ATS file containing airway segments.\n",
    "    \n",
    "    The ATS file is expected to have header lines for each airway (starting with \"A\")\n",
    "    and segment lines (starting with \"S\"). For example:\n",
    "    \n",
    "      A,A1,46\n",
    "      S,KEC,33.447742,135.794494,ALBAT,33.364503,135.441514,0,262,18.37\n",
    "      S,ALBAT,33.364503,135.441514,HALON,33.248769,134.997222,260,262,23.34\n",
    "      ...\n",
    "      \n",
    "    For each \"S\" (segment) line, this function:\n",
    "      - Parses the start and end fixes and their coordinates.\n",
    "      - Filters out segments if either endpoint is not within Europe.\n",
    "      - Adds fixes (nodes) to the graph.\n",
    "      - Adds an edge for the segment with attributes for minimum altitude,\n",
    "        maximum altitude, distance, and the airway name.\n",
    "    \n",
    "    Parameters:\n",
    "      filename (str): Path to the ATS data file.\n",
    "      bidirectional (bool): If True, add edges in both directions.\n",
    "    \n",
    "    Returns:\n",
    "      networkx.DiGraph: The directed graph representing ATS fixes and segments.\n",
    "    \"\"\"\n",
    "    # Create a directed graph; convert later to undirected if needed.\n",
    "    G = nx.DiGraph()\n",
    "    current_airway = \"Unknown\"  # Default airway name if header hasn't been seen\n",
    "\n",
    "    with open(filename, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if not line or line.startswith(\"#\"):\n",
    "                continue  # Skip empty or comment lines\n",
    "\n",
    "            parts = line.split(',')\n",
    "            record_type = parts[0].strip().upper()\n",
    "\n",
    "            # If the line is an airway header, update the current airway name.\n",
    "            if record_type == \"A\":\n",
    "                if len(parts) >= 2:\n",
    "                    current_airway = parts[1].strip()\n",
    "                    # Append two random digits to the airway name to make it unique\n",
    "                    current_airway = current_airway + generate_random_two_digits()\n",
    "                continue\n",
    "\n",
    "\n",
    "            # Process only segment lines.\n",
    "            if record_type != \"S\":\n",
    "                continue\n",
    "\n",
    "            if len(parts) < 10:\n",
    "                print(f\"Skipping malformed line: {line}\")\n",
    "                continue\n",
    "\n",
    "            # Unpack fields from the segment line.\n",
    "            # Format: S, start_fix, start_lat, start_lon, end_fix, end_lat, end_lon, min_alt, max_alt, distance\n",
    "            (_, start_fix, start_lat, start_lon, end_fix, end_lat, end_lon,\n",
    "             min_alt, max_alt, distance) = parts\n",
    "            \n",
    "            # Append two random digits to the start and end fixes to make them unique\n",
    "            start_fix = start_fix + generate_random_two_digits()\n",
    "            end_fix = end_fix + generate_random_two_digits()\n",
    "\n",
    "            # Convert coordinate and numeric fields.\n",
    "            try:\n",
    "                start_lat = float(start_lat)\n",
    "                start_lon = float(start_lon)\n",
    "                end_lat   = float(end_lat)\n",
    "                end_lon   = float(end_lon)\n",
    "                min_alt   = float(min_alt)\n",
    "                max_alt   = float(max_alt)\n",
    "                distance  = float(distance)\n",
    "            except ValueError:\n",
    "                print(f\"Skipping line due to conversion error: {line}\")\n",
    "                continue\n",
    "\n",
    "            # Filter: Only include segments with both endpoints in Europe.\n",
    "            if not (is_in_europe(start_lat, start_lon) and is_in_europe(end_lat, end_lon)):\n",
    "                # Uncomment the next line to see which segments are skipped.\n",
    "                # print(f\"Skipping non-European segment: {start_fix} -> {end_fix}\")\n",
    "                continue\n",
    "\n",
    "            # Add the nodes (fixes) with their coordinates.\n",
    "            if start_fix not in G:\n",
    "                G.add_node(start_fix, lat=start_lat, lon=start_lon)\n",
    "            if end_fix not in G:\n",
    "                G.add_node(end_fix, lat=end_lat, lon=end_lon)\n",
    "\n",
    "            # Add the edge (segment) with its attributes, including the airway name.\n",
    "            edge_attrs = {\n",
    "                'min_alt': min_alt,\n",
    "                'max_alt': max_alt,\n",
    "                'distance': distance,\n",
    "                'airway': current_airway,\n",
    "                'edge_type': 'airway'\n",
    "            }\n",
    "            G.add_edge(start_fix, end_fix, **edge_attrs)\n",
    "\n",
    "\n",
    "            # Optionally, add the reverse edge if the segment is bidirectional.\n",
    "            if bidirectional:\n",
    "                G.add_edge(end_fix, start_fix, **edge_attrs)\n",
    "\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph_from_waypoints(filename):\n",
    "    \"\"\"\n",
    "    Builds a graph from a Waypoints file containing fix positions.\n",
    "    \n",
    "    The Waypoints file is expected to have lines with the format:\n",
    "    fix_name,latitude,longitude,unused_field\n",
    "    \n",
    "    For example:\n",
    "      0000E,0.000000,0.000000,  \n",
    "      0000N,0.000000,0.000000,  \n",
    "    \n",
    "    For each line, this function:\n",
    "      - Parses the fix name and its coordinates\n",
    "      - Filters out fixes that are not within Europe\n",
    "      - Adds the fix as a node to the graph with its coordinates\n",
    "    \n",
    "    Parameters:\n",
    "      filename (str): Path to the Waypoints data file.\n",
    "    \n",
    "    Returns:\n",
    "      networkx.Graph: The undirected graph containing waypoint nodes.\n",
    "    \"\"\"\n",
    "    # Create an undirected graph since we're only adding nodes\n",
    "    G = nx.Graph()\n",
    "\n",
    "    with open(filename, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if not line or line.startswith(\"#\"):\n",
    "                continue  # Skip empty or comment lines\n",
    "\n",
    "            parts = line.split(',')\n",
    "            if len(parts) < 3:\n",
    "                print(f\"Skipping malformed line: {line}\")\n",
    "                continue\n",
    "\n",
    "            # Unpack fields from the line\n",
    "            fix_name, lat, lon = parts[:3]\n",
    "            \n",
    "            # Append two random digits to the fix name to make it unique\n",
    "            fix_name = fix_name + generate_random_two_digits()\n",
    "\n",
    "            # Convert coordinate fields\n",
    "            try:\n",
    "                lat = float(lat)\n",
    "                lon = float(lon)\n",
    "            except ValueError:\n",
    "                print(f\"Skipping line due to conversion error: {line}\")\n",
    "                continue\n",
    "\n",
    "            # Filter: Only include fixes in Europe\n",
    "            if not is_in_europe(lat, lon):\n",
    "                # Uncomment the next line to see which fixes are skipped\n",
    "                # print(f\"Skipping non-European fix: {fix_name}\")\n",
    "                continue\n",
    "\n",
    "            # Add the node (fix) with its coordinates\n",
    "            G.add_node(fix_name, lat=lat, lon=lon)\n",
    "\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATS graph saved to: E:/project-akrav\\data\\graphs\\ats_graph.graphml\n",
      "Number of fixes (nodes): 54983\n",
      "Number of route segments (edges): 28950\n",
      "--------------------------------\n",
      "Waypoints graph saved to: E:/project-akrav\\data\\graphs\\waypoints_graph.graphml\n",
      "Number of fixes (nodes): 59362\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "ats_file = os.path.join(PROJECT_ROOT, \"data\", \"airac\", \"ATS.txt\")\n",
    "\n",
    "# Set bidirectional=True if segments are used in both directions.\n",
    "graph_ats = build_graph_from_ats(ats_file, bidirectional=False)\n",
    "\n",
    "# Define the output path for the graph file\n",
    "graph_output_path = os.path.join(PROJECT_ROOT, \"data\", \"graphs\", \"ats_graph.graphml\")\n",
    "\n",
    "# Ensure the directory exists\n",
    "os.makedirs(os.path.dirname(graph_output_path), exist_ok=True)\n",
    "\n",
    "# Save the graph in GraphML format\n",
    "nx.write_graphml(graph_ats, graph_output_path)\n",
    "print(f\"ATS graph saved to: {graph_output_path}\")\n",
    "\n",
    "\n",
    "print(f\"Number of fixes (nodes): {graph_ats.number_of_nodes()}\")\n",
    "print(f\"Number of route segments (edges): {graph_ats.number_of_edges()}\")\n",
    "\n",
    "print('--------------------------------')\n",
    "\n",
    "# Build the waypoints graph\n",
    "waypoints_file = os.path.join(PROJECT_ROOT, \"data\", \"airac\", \"WAYPOINTS.txt\")\n",
    "graph_waypoints = build_graph_from_waypoints(waypoints_file)\n",
    "\n",
    "# Define the output path for the waypoints graph file\n",
    "waypoints_output_path = os.path.join(PROJECT_ROOT, \"data\", \"graphs\", \"waypoints_graph.graphml\")\n",
    "\n",
    "# Ensure the directory exists\n",
    "os.makedirs(os.path.dirname(waypoints_output_path), exist_ok=True)\n",
    "\n",
    "# Save the waypoints graph in GraphML format\n",
    "nx.write_graphml(graph_waypoints, waypoints_output_path)\n",
    "print(f\"Waypoints graph saved to: {waypoints_output_path}\")\n",
    "print(f\"Number of fixes (nodes): {graph_waypoints.number_of_nodes()}\")\n",
    "print('--------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_waypoints(graph_waypoints):\n",
    "    \"\"\"\n",
    "    Groups waypoints that are within 10 nautical miles of each other using a grid-based approach.\n",
    "    \n",
    "    Parameters:\n",
    "        graph_waypoints (networkx.Graph): Graph containing waypoints as nodes with lat/lon attributes\n",
    "        \n",
    "    Returns:\n",
    "        dict: Mapping of original waypoint names to their group IDs\n",
    "    \"\"\"\n",
    "    from math import radians, cos, sin, asin, sqrt\n",
    "    import numpy as np\n",
    "    \n",
    "    def haversine(lat1, lon1, lat2, lon2):\n",
    "        \"\"\"Calculate haversine distance in nautical miles\"\"\"\n",
    "        R = 3440.065  # Earth's radius in nautical miles\n",
    "        \n",
    "        lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])\n",
    "        dlat = lat2 - lat1\n",
    "        dlon = lon2 - lon1\n",
    "        \n",
    "        a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "        c = 2 * asin(sqrt(a))\n",
    "        return R * c\n",
    "    \n",
    "    # Convert 10 nautical miles to approximate degrees at the equator\n",
    "    # (1 degree ≈ 60 nautical miles)\n",
    "    grid_size = 10/60  # degrees\n",
    "    \n",
    "    # Initialize grid cells dictionary\n",
    "    grid_cells = {}\n",
    "    waypoint_groups = {}\n",
    "    current_group = 0\n",
    "    \n",
    "    # First pass: Assign waypoints to grid cells\n",
    "    for node in graph_waypoints.nodes():\n",
    "        lat = graph_waypoints.nodes[node]['lat']\n",
    "        lon = graph_waypoints.nodes[node]['lon']\n",
    "        \n",
    "        # Calculate grid cell indices\n",
    "        cell_lat = int(lat / grid_size)\n",
    "        cell_lon = int(lon / grid_size)\n",
    "        \n",
    "        # Store waypoint in grid cell\n",
    "        cell_key = (cell_lat, cell_lon)\n",
    "        if cell_key not in grid_cells:\n",
    "            grid_cells[cell_key] = []\n",
    "        grid_cells[cell_key].append((node, lat, lon))\n",
    "    \n",
    "    # Second pass: Group waypoints\n",
    "    processed = set()\n",
    "    \n",
    "    for cell_key, waypoints in grid_cells.items():\n",
    "        # Get neighboring cells\n",
    "        cell_lat, cell_lon = cell_key\n",
    "        neighbor_cells = [\n",
    "            (cell_lat + i, cell_lon + j)\n",
    "            for i in [-1, 0, 1]\n",
    "            for j in [-1, 0, 1]\n",
    "        ]\n",
    "        \n",
    "        for waypoint, lat1, lon1 in waypoints:\n",
    "            if waypoint in processed:\n",
    "                continue\n",
    "                \n",
    "            # Start a new group\n",
    "            current_group_waypoints = []\n",
    "            \n",
    "            # Check waypoints in current and neighboring cells\n",
    "            for neighbor_cell in neighbor_cells:\n",
    "                if neighbor_cell not in grid_cells:\n",
    "                    continue\n",
    "                    \n",
    "                for other_waypoint, lat2, lon2 in grid_cells[neighbor_cell]:\n",
    "                    if other_waypoint in processed:\n",
    "                        continue\n",
    "                        \n",
    "                    if haversine(lat1, lon1, lat2, lon2) <= 10:\n",
    "                        current_group_waypoints.append(other_waypoint)\n",
    "                        processed.add(other_waypoint)\n",
    "            \n",
    "            if current_group_waypoints:\n",
    "                for wp in current_group_waypoints:\n",
    "                    waypoint_groups[wp] = current_group\n",
    "                current_group += 1\n",
    "            \n",
    "            processed.add(waypoint)\n",
    "    \n",
    "    # Handle any remaining unprocessed waypoints\n",
    "    for node in graph_waypoints.nodes():\n",
    "        if node not in waypoint_groups:\n",
    "            waypoint_groups[node] = current_group\n",
    "            current_group += 1\n",
    "    \n",
    "    return waypoint_groups\n",
    "\n",
    "waypoint_groups = group_waypoints(graph_waypoints)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original graph nodes: 59362\n",
      "Reduced graph nodes: 13698\n",
      "Reduced waypoints graph saved to: E:/project-akrav\\data\\graphs\\reduced_waypoints_graph.graphml\n"
     ]
    }
   ],
   "source": [
    "def reduce_graph_by_groups(graph, waypoint_groups):\n",
    "    \"\"\"\n",
    "    Reduces the graph by selecting one representative node per group.\n",
    "    \n",
    "    Parameters:\n",
    "        graph (networkx.Graph): Original graph containing waypoints\n",
    "        waypoint_groups (dict): Mapping of waypoint names to their group IDs\n",
    "        \n",
    "    Returns:\n",
    "        networkx.Graph: Reduced graph with one waypoint per group\n",
    "    \"\"\"\n",
    "    import networkx as nx\n",
    "    \n",
    "    # Create a new graph for the reduced version\n",
    "    reduced_graph = nx.Graph()\n",
    "    \n",
    "    # Create reverse mapping from group ID to list of waypoints\n",
    "    group_to_waypoints = {}\n",
    "    for waypoint, group_id in waypoint_groups.items():\n",
    "        if group_id not in group_to_waypoints:\n",
    "            group_to_waypoints[group_id] = []\n",
    "        group_to_waypoints[group_id].append(waypoint)\n",
    "    \n",
    "    # For each group, select a representative waypoint\n",
    "    # (here we choose the first waypoint in each group)\n",
    "    for group_id, waypoints in group_to_waypoints.items():\n",
    "        representative = waypoints[0]\n",
    "        # Copy the node and its attributes to the reduced graph\n",
    "        reduced_graph.add_node(representative, **graph.nodes[representative])\n",
    "    \n",
    "    return reduced_graph\n",
    "\n",
    "# Use the function\n",
    "reduced_waypoints_graph = reduce_graph_by_groups(graph_waypoints, waypoint_groups)\n",
    "\n",
    "print(f\"Original graph nodes: {graph_waypoints.number_of_nodes()}\")\n",
    "print(f\"Reduced graph nodes: {reduced_waypoints_graph.number_of_nodes()}\")\n",
    "\n",
    "# Save the reduced graph\n",
    "reduced_output_path = os.path.join(PROJECT_ROOT, \"data\", \"graphs\", \"reduced_waypoints_graph.graphml\")\n",
    "nx.write_graphml(reduced_waypoints_graph, reduced_output_path)\n",
    "print(f\"Reduced waypoints graph saved to: {reduced_output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68424/68424 [11:36<00:00, 98.26it/s]  \n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "from geopy.distance import geodesic\n",
    "from sklearn.neighbors import BallTree\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def merge_graphs_balltree(graph_ats, reduced_waypoints_graph,\n",
    "                          max_dct_distance):\n",
    "    \"\"\"\n",
    "    Merge the ATS (airway) graph with the waypoint graph and add potential DCT (direct) edges.\n",
    "    Uses a BallTree for efficiently finding nodes that are close enough.\n",
    "    \n",
    "    Parameters:\n",
    "      graph_ats: networkx DiGraph with nodes and published airway edges.\n",
    "      reduced_waypoints_graph: networkx Graph (or DiGraph) with additional waypoint nodes.\n",
    "      ct: time cost (currency per hour) for cost computation.\n",
    "      cf: fuel cost (currency per kg) for cost computation.\n",
    "      max_dct_distance: maximum distance (nm) within which to add a DCT edge.\n",
    "      \n",
    "      \n",
    "    Returns:\n",
    "      G_merged: A networkx DiGraph that includes:\n",
    "          - All nodes from both graphs.\n",
    "          - All original ATS (airway) edges.\n",
    "          - Additional DCT edges (with attributes) connecting nodes that are within\n",
    "            max_dct_distance and are not already connected by an airway edge.\n",
    "    \"\"\"\n",
    "    \n",
    "    # --- Step 1. Merge nodes and ATS edges into a new graph ---\n",
    "    G_merged = nx.DiGraph()\n",
    "    \n",
    "    # Add ATS nodes and edges\n",
    "    for node, data in graph_ats.nodes(data=True):\n",
    "        G_merged.add_node(node, **data)\n",
    "    for u, v, data in graph_ats.edges(data=True):\n",
    "        G_merged.add_edge(u, v, **data)\n",
    "    \n",
    "    # Add waypoint nodes that are not already present\n",
    "    for node, data in reduced_waypoints_graph.nodes(data=True):\n",
    "        if node not in G_merged:\n",
    "            G_merged.add_node(node, **data)\n",
    "    \n",
    "    # --- Step 2. Build a BallTree of nodes with valid coordinates ---\n",
    "    # Create a list of nodes (identifiers) and a corresponding coordinate array in radians.\n",
    "    all_nodes = list(G_merged.nodes())\n",
    "    coords = []\n",
    "    valid_node_indices = []  # indices for which we have valid coordinates\n",
    "    valid_nodes = []         # corresponding node ids\n",
    "    \n",
    "    for idx, node in enumerate(all_nodes):\n",
    "        data = G_merged.nodes[node]\n",
    "        lat = data.get('lat')\n",
    "        lon = data.get('lon')\n",
    "        if lat is None or lon is None:\n",
    "            # Skip nodes without valid coordinate data\n",
    "            coords.append((np.nan, np.nan))\n",
    "        else:\n",
    "            # Convert to radians: [latitude, longitude]\n",
    "            coords.append((np.radians(lat), np.radians(lon)))\n",
    "            valid_node_indices.append(idx)\n",
    "            valid_nodes.append(node)\n",
    "    \n",
    "    coords = np.array(coords)\n",
    "    \n",
    "    # Filter out nodes with missing coordinates for building the tree\n",
    "    valid_coords = coords[valid_node_indices]\n",
    "    if len(valid_coords) == 0:\n",
    "        # No valid nodes: nothing to add.\n",
    "        return G_merged\n",
    "\n",
    "    # Build the BallTree using haversine metric.\n",
    "    ball_tree = BallTree(valid_coords, metric='haversine')\n",
    "    \n",
    "    # --- Step 3. Query the BallTree to add potential DCT edges ---\n",
    "    # Earth radius in nautical miles (approximate)\n",
    "    earth_radius_nm = 3440.065\n",
    "    # Convert max_dct_distance (nm) to radians.\n",
    "    radius_radians = max_dct_distance / earth_radius_nm\n",
    "    \n",
    "    # Query: for each valid node, find neighbors within the specified radius.\n",
    "    # query_radius returns an array (one per point) of indices into valid_coords.\n",
    "    neighbors_indices = ball_tree.query_radius(valid_coords, r=radius_radians)\n",
    "    \n",
    "    # Loop over each valid node and its neighbors\n",
    "    for i, neighbor_idxs in tqdm(enumerate(neighbors_indices), total=len(neighbors_indices)):\n",
    "        node_u = valid_nodes[i]\n",
    "        data_u = G_merged.nodes[node_u]\n",
    "        lat_u = data_u.get('lat')\n",
    "        lon_u = data_u.get('lon')\n",
    "        for j in neighbor_idxs:\n",
    "\n",
    "            if i == j:\n",
    "                continue  # Skip self\n",
    "            node_v = valid_nodes[j]\n",
    "            # If there is already an edge from node_u to node_v (an ATS edge), skip.\n",
    "            if G_merged.has_edge(node_u, node_v):\n",
    "                continue\n",
    "            data_v = G_merged.nodes[node_v]\n",
    "            lat_v = data_v.get('lat')\n",
    "            lon_v = data_v.get('lon')\n",
    "            # Compute the geodesic distance in nautical miles.\n",
    "            distance = geodesic((lat_u, lon_u), (lat_v, lon_v)).nautical\n",
    "            if distance > max_dct_distance:\n",
    "                continue  # Skip if outside desired threshold (can happen near the boundary)\n",
    "            \n",
    "            # Create the DCT edge data.\n",
    "            dct_edge_data = {\n",
    "                'distance': distance,\n",
    "                'min_alt': 0,\n",
    "                'max_alt': 0,\n",
    "                'airway': '',\n",
    "                'edge_type': 'DCT'  # mark the edge as a direct (DCT) edge\n",
    "            }\n",
    "            G_merged.add_edge(node_u, node_v, **dct_edge_data)\n",
    "            G_merged.add_edge(node_v, node_u, **dct_edge_data)\n",
    "\n",
    "    \n",
    "\n",
    "    return G_merged\n",
    "\n",
    "merged_graph = merge_graphs_balltree(graph_ats, reduced_waypoints_graph, 40)\n",
    "# Write the merged graph to a file\n",
    "nx.write_gml(merged_graph, os.path.join(PROJECT_ROOT, \"data\", \"graphs\", \"route_graph.gml\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 539412 duplicate nodes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 539412/539412 [00:25<00:00, 21060.11it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 49637 duplicate nodes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def collapse_duplicate_nodes(graph):\n",
    "    \"\"\"\n",
    "    Collapses nodes that are extremely close together (distance < 0.001 nm).\n",
    "    When nodes are collapsed, one node is kept and the other is removed, with all edges\n",
    "    redirected to the remaining node.\n",
    "    \n",
    "    Args:\n",
    "        graph: NetworkX graph to process\n",
    "        \n",
    "    Returns:\n",
    "        Modified graph with duplicate nodes collapsed\n",
    "    \"\"\"\n",
    "    G = graph.copy()\n",
    "    \n",
    "    # Find pairs of nodes to collapse\n",
    "    nodes_to_merge = []\n",
    "    for u, v, data in G.edges(data=True):\n",
    "        if data['distance'] < 0.001:\n",
    "            nodes_to_merge.append((u, v))\n",
    "\n",
    "    nodes_removed = 0\n",
    "    print(f'Found {len(nodes_to_merge)} duplicate nodes')\n",
    "    \n",
    "    # For each pair of nodes to merge\n",
    "    for node1, node2 in tqdm(nodes_to_merge, total=len(nodes_to_merge)):\n",
    "        if node1 not in G.nodes() or node2 not in G.nodes():\n",
    "            continue # Skip if either node was already removed\n",
    "            \n",
    "\n",
    "        # Get all edges connected to node2\n",
    "        edges_to_redirect = list(G.in_edges(node2, data=True)) + list(G.out_edges(node2, data=True))\n",
    "        \n",
    "        # Redirect all edges from/to node2 to instead connect with node1\n",
    "        for u, v, data in edges_to_redirect:\n",
    "            if u == node2:\n",
    "                if v != node1:  # Avoid self loops\n",
    "                    G.add_edge(node1, v, **data)\n",
    "            elif v == node2:\n",
    "                if u != node1:  # Avoid self loops\n",
    "                    G.add_edge(u, node1, **data)\n",
    "                    \n",
    "        # Remove the duplicate node\n",
    "        G.remove_node(node2)\n",
    "        nodes_removed += 1\n",
    "\n",
    "    print(f\"Removed {nodes_removed} duplicate nodes\")\n",
    "\n",
    "    return G\n",
    "\n",
    "collapsed_graph = collapse_duplicate_nodes(merged_graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged graph nodes: 18787\n",
      "Merged graph edges: 513277\n"
     ]
    }
   ],
   "source": [
    "print(f\"Merged graph nodes: {collapsed_graph.number_of_nodes()}\")\n",
    "print(f\"Merged graph edges: {collapsed_graph.number_of_edges()}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the merged graph to a file\n",
    "nx.write_gml(collapsed_graph, os.path.join(PROJECT_ROOT, \"data\", \"graphs\", \"route_graph_reduced.gml\"))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Airport data saved to: E:/project-akrav\\data\\airac\\airports.csv\n"
     ]
    }
   ],
   "source": [
    "def generate_airport_csv(filename):\n",
    "    \"\"\"\n",
    "    Extracts airport information from Airport.txt and saves it to a CSV file.\n",
    "    \n",
    "    Airport line format:\n",
    "    A,ICAO,NAME,LAT,LON,ELEV,LENGTH,UNUSED1,UNUSED2,UNUSED3\n",
    "    \n",
    "    Parameters:\n",
    "        filename (str): Path to the Airport.txt file\n",
    "    \"\"\"\n",
    "    import csv\n",
    "    import os\n",
    "    \n",
    "    output_file = os.path.join(os.path.dirname(filename), 'airports.csv')\n",
    "    \n",
    "    # Define CSV headers\n",
    "    headers = ['icao', 'name', 'latitude', 'longitude', 'elevation']\n",
    "    \n",
    "    with open(filename, 'r') as infile, open(output_file, 'w', newline='') as outfile:\n",
    "        writer = csv.writer(outfile)\n",
    "        writer.writerow(headers)\n",
    "        \n",
    "        for line in infile:\n",
    "            line = line.strip()\n",
    "            if not line or not line.startswith('A'):\n",
    "                continue\n",
    "                \n",
    "            parts = line.split(',')\n",
    "            if len(parts) < 5:\n",
    "                continue\n",
    "                \n",
    "            # Extract relevant fields\n",
    "            icao = parts[1]\n",
    "            name = parts[2]\n",
    "            try:\n",
    "                lat = float(parts[3])\n",
    "                lon = float(parts[4])\n",
    "                elev = float(parts[5])\n",
    "            except (ValueError, IndexError):\n",
    "                print(f\"Skipping malformed line: {line}\")\n",
    "                continue\n",
    "                \n",
    "            writer.writerow([icao, name, lat, lon, elev])\n",
    "    \n",
    "    print(f\"Airport data saved to: {output_file}\")\n",
    "\n",
    "# Usage:\n",
    "airport_file = os.path.join(PROJECT_ROOT, \"data\", \"airac\", \"Airports.txt\")\n",
    "generate_airport_csv(airport_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lat': 51.235314, 'lon': 3.869711}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find node HELEN13 in the merged_graph\n",
    "merged_graph.nodes['HELEN13']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lat': 51.235314, 'lon': 3.869711}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collapsed_graph.nodes['HELEN13']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mayflower",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
