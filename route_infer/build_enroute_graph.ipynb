{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "PROJECT_ROOT = os.getenv('PROJECT_ROOT')\n",
    "\n",
    "# Add PROJECT_ROOT to the Python path\n",
    "import sys\n",
    "sys.path.append(PROJECT_ROOT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Airports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "airports_df = pd.read_csv(os.path.join(PROJECT_ROOT, \"data\", \"airac\", \"airports.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base ATS Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "ats_graph = nx.read_graphml(os.path.join(PROJECT_ROOT, \"data\", \"graphs\", \"ats_graph.graphml\"))\n",
    "print(f'ATS graph loaded with {len(ats_graph.nodes())} nodes and {len(ats_graph.edges())} edges')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Free Route Airspace (FRA) Assimilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fra_df = pd.read_csv(os.path.join(PROJECT_ROOT, \"data\", \"rad\", \"FRA_PTS.csv\"))\n",
    "fra_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_coord_for_fra_df(coord_str):\n",
    "        \"\"\"Convert coordinates from format like 'N404519' or 'E0183830' to decimal degrees\"\"\"\n",
    "        try:\n",
    "            direction = coord_str[0]\n",
    "            degrees = float(coord_str[1:-4])\n",
    "            decimals = float(coord_str[-4:]) / 10000\n",
    "            decimal = round(degrees + decimals, 4)\n",
    "            return decimal if direction in ['N', 'E'] else -decimal\n",
    "        except (ValueError, IndexError):\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from utils.haversine import haversine_distance\n",
    "\n",
    "def generate_random_two_digits():\n",
    "    return str(random.randint(0, 99)).zfill(2)\n",
    "\n",
    "def add_node_with_refs(G, node_id, lat, lon, type='FRA'):\n",
    "    if node_id in G.nodes:\n",
    "        # Fix already exists, check if coordinates match\n",
    "        if abs(G.nodes[node_id]['lat'] - lat) > 1e-4 or abs(G.nodes[node_id]['lon'] - lon) > 1e-4:\n",
    "            # print(f\"Fix {node_id} has different coordinates: {G.nodes[node_id]['lat']}, {G.nodes[node_id]['lon']} != {lat}, {lon}\")\n",
    "            original_node_id = node_id\n",
    "            node_id = node_id + '_' + generate_random_two_digits()\n",
    "            G.add_node(node_id, lat=lat, lon=lon, type=type, refs='')\n",
    "            # Modify the refs of the original node\n",
    "            \n",
    "            if 'refs' in G.nodes[original_node_id]:\n",
    "                original_node_id_refs = G.nodes[original_node_id]['refs']\n",
    "            else: \n",
    "                original_node_id_refs = ''\n",
    "                \n",
    "            G.nodes[original_node_id]['refs'] = original_node_id_refs + f'{node_id}, '\n",
    "        return node_id\n",
    "    else:\n",
    "        G.add_node(node_id, lat=lat, lon=lon, type=type, refs='')\n",
    "        return node_id\n",
    "    \n",
    "def create_edge_with_closest_refs(graph_ats, from_fix, to_fix, threshold = 100, type='DCT'):\n",
    "    if graph_ats.has_edge(from_fix, to_fix):\n",
    "        return\n",
    "    from_fix_lat = graph_ats.nodes[from_fix]['lat']\n",
    "    from_fix_lon = graph_ats.nodes[from_fix]['lon']\n",
    "    to_fix_lat = graph_ats.nodes[to_fix]['lat']\n",
    "    to_fix_lon = graph_ats.nodes[to_fix]['lon']\n",
    "    distance = haversine_distance(from_fix_lat, from_fix_lon, to_fix_lat, to_fix_lon)\n",
    "    \n",
    "    # print(f'DCT link between {from_fix} and {to_fix} is {distance:.2f}nm. Considering alternatives...')\n",
    "    if distance < threshold:\n",
    "        if not graph_ats.has_edge(from_fix, to_fix):\n",
    "            graph_ats.add_edge(from_fix, to_fix,\n",
    "                            distance=distance,\n",
    "                            airway='',\n",
    "                            edge_type=type)\n",
    "        return # do nothing if the distance is less than the threshold\n",
    "    \n",
    "    if 'refs' in graph_ats.nodes[from_fix]:\n",
    "        from_fix_refs = graph_ats.nodes[from_fix]['refs']\n",
    "    else:\n",
    "        from_fix_refs = ''\n",
    "    if 'refs' in graph_ats.nodes[to_fix]:\n",
    "        to_fix_refs = graph_ats.nodes[to_fix]['refs']\n",
    "    else:\n",
    "        to_fix_refs = ''\n",
    "    # Split refs strings into lists\n",
    "    from_fix_refs = from_fix_refs.split(',') if from_fix_refs else []\n",
    "    to_fix_refs = to_fix_refs.split(',') if to_fix_refs else []\n",
    "    if len(from_fix_refs) == 0 and len(to_fix_refs) == 0:\n",
    "        # No refs, add the edge directly\n",
    "        if not graph_ats.has_edge(from_fix, to_fix):\n",
    "            graph_ats.add_edge(from_fix, to_fix,\n",
    "                            distance=distance,\n",
    "                            airway='',\n",
    "                            edge_type=type)\n",
    "        return\n",
    "    # Add the current fixes to the refs\n",
    "    from_fix_refs.append(from_fix)\n",
    "    to_fix_refs.append(to_fix)\n",
    "    \n",
    "    # Find the closest pair of refs\n",
    "    min_distance = float('inf')\n",
    "    best_from_ref = None \n",
    "    best_to_ref = None\n",
    "    \n",
    "    for from_ref in from_fix_refs:\n",
    "        if from_ref not in graph_ats.nodes:\n",
    "            continue\n",
    "        for to_ref in to_fix_refs:\n",
    "            if to_ref not in graph_ats.nodes:\n",
    "                continue\n",
    "            # Get coordinates\n",
    "            from_ref_lat = graph_ats.nodes[from_ref]['lat']\n",
    "            from_ref_lon = graph_ats.nodes[from_ref]['lon']\n",
    "            to_ref_lat = graph_ats.nodes[to_ref]['lat']\n",
    "            to_ref_lon = graph_ats.nodes[to_ref]['lon']\n",
    "            \n",
    "            # Calculate simple distance (absolute difference)\n",
    "            dist = abs(from_ref_lat - to_ref_lat) + abs(from_ref_lon - to_ref_lon)\n",
    "            \n",
    "            if dist < min_distance:\n",
    "                min_distance = dist\n",
    "                best_from_ref = from_ref\n",
    "                best_to_ref = to_ref\n",
    "\n",
    "    # Recalculate the distance in nm\n",
    "    best_min_distance = haversine_distance(\n",
    "        graph_ats.nodes[best_from_ref]['lat'], \n",
    "        graph_ats.nodes[best_from_ref]['lon'], \n",
    "        graph_ats.nodes[best_to_ref]['lat'], \n",
    "        graph_ats.nodes[best_to_ref]['lon']\n",
    "    )\n",
    "    \n",
    "    # Create edge between closest refs if found\n",
    "    if best_from_ref and best_to_ref:\n",
    "        if not graph_ats.has_edge(best_from_ref, best_to_ref):\n",
    "            graph_ats.add_edge(best_from_ref, best_to_ref,\n",
    "                            distance=best_min_distance,\n",
    "                            airway='',\n",
    "                            edge_type=type)\n",
    "            # print(f'Established link between {best_from_ref} and {best_to_ref} instead. New distance is {best_min_distance}')\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def load_fra_graph_into_ats_graph(ats_graph, fra_df = None, fra_df_path = None):\n",
    "    \n",
    "    ats_graph = ats_graph.copy()\n",
    "    fra_df = fra_df.copy()\n",
    "\n",
    "    print(f'Building FRA routing options...')\n",
    "    # Load the FRA graph from a GraphML file\n",
    "    if fra_df is None:\n",
    "        if fra_df_path is None:\n",
    "            raise ValueError(\"Either fra_graph or fra_graph_path must be provided\")\n",
    "        fra_df = pd.read_csv(fra_df_path)\n",
    "        # columns of fra_df: chg_rec,pt_type,fra_pt,fra_lat,fra_lon,fra_name,fra_rel_enroute,fra_rel_arr_dep,arr_apt,dep_apt,flos,lvl_avail,time_avail,loc_ind,rmk\n",
    "\n",
    "    # Uppercase and strip the fra_name column to standardize the names\n",
    "    fra_df['fra_name'] = fra_df['fra_name'].str.upper().str.strip()\n",
    "\n",
    "    # Convert fra_lat and fra_lon to decimal degrees\n",
    "    fra_df['fra_lat'] = fra_df['fra_lat'].apply(convert_coord_for_fra_df)\n",
    "    fra_df['fra_lon'] = fra_df['fra_lon'].apply(convert_coord_for_fra_df)\n",
    "    \n",
    "    fra_names = fra_df['fra_name'].unique()\n",
    "\n",
    "    for fra in fra_names:\n",
    "        fra_df_subset = fra_df[fra_df['fra_name'] == fra]\n",
    "        # Add all FRA points from this subset to the graph if they don't exist\n",
    "        fra_map = {} # stores mapping ABADI -> ABADI_01 if they are not unique\n",
    "        for _, row in fra_df_subset.iterrows():\n",
    "            node_id = row['fra_pt']\n",
    "            renamed_id = add_node_with_refs(ats_graph, node_id, row['fra_lat'], row['fra_lon'], type='FRA')\n",
    "            if renamed_id != node_id:\n",
    "                fra_map[node_id] = renamed_id\n",
    "\n",
    "        print(f'{len(fra_map)} FRA points renamed for {fra}')\n",
    "\n",
    "        # Get all FRA points for this name and their types\n",
    "        fra_points = [(row['fra_pt'], row['fra_rel_enroute']) \n",
    "                     for _, row in fra_df_subset.iterrows()]\n",
    "\n",
    "        # Rename fra_points using fra_map if any points were renamed\n",
    "        # fra_points = [(fra_map.get(point, point), type_) \n",
    "        #              for point, type_ in fra_points]\n",
    "\n",
    "        # Connect points according to rules\n",
    "        for point1, type1 in tqdm(fra_points, desc=f\"{fra}\"):\n",
    "            for point2, type2 in fra_points:\n",
    "                # Skip self-connections\n",
    "                if point1 == point2:\n",
    "                    continue\n",
    "                    \n",
    "                # Rule 2: EX can connect to X, EX or I\n",
    "                if type1 == 'EX' and type2 in ['X', 'EX', 'I']:\n",
    "                    create_edge_with_closest_refs(ats_graph, point1, point2, threshold=150, type='FRA')\n",
    "                \n",
    "                # Rule 3: E can connect to X, EX or I  \n",
    "                elif type1 == 'E' and type2 in ['X', 'EX', 'I']:\n",
    "                    create_edge_with_closest_refs(ats_graph, point1, point2, threshold=150, type='FRA')\n",
    "                \n",
    "                # Rule 4: I can connect bilaterally to I\n",
    "                elif type1 == 'I' and type2 == 'I':\n",
    "                    create_edge_with_closest_refs(ats_graph, point1, point2, threshold=150, type='FRA')\n",
    "    \n",
    "    print(f'FRA graph merged into ATS graph. Nodes: {ats_graph.number_of_nodes()}, edges: {ats_graph.number_of_edges()}')\n",
    "    return ats_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ats_fra = load_fra_graph_into_ats_graph(ats_graph, fra_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the ats_fra graph to a file in GraphML format (most compact format for NetworkX graphs)\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "output_dir = Path(os.getenv('PROJECT_ROOT', '.')) / 'data' / 'graphs'\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save the graph\n",
    "output_path = output_dir / 'ats_fra_graph.gml'\n",
    "import networkx as nx\n",
    "nx.write_gml(ats_fra, output_path)\n",
    "\n",
    "print(f\"Graph saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the size of the graph saved\n",
    "print(f\"Graph size: {os.path.getsize(output_path)} bytes or {os.path.getsize(output_path) / 1024 / 1024:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build an edge free graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, os\n",
    "time_start = time.time()\n",
    "print('Reading navigation graph...')\n",
    "import pickle\n",
    "G = pickle.load(open(os.path.join(PROJECT_ROOT, 'data', 'graphs', 'ats_fra_graph.pkl'), 'rb'))\n",
    "print(f'Navigation graph loaded in {time.time() - time_start:.2f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "# Create a new graph with only the nodes from G, but no edges\n",
    "print('Creating a new graph with only nodes (no edges)...')\n",
    "start_time = time.time()\n",
    "\n",
    "# Create an empty graph with the same graph type as G\n",
    "node_only_graph = nx.Graph() if isinstance(G, nx.Graph) else nx.DiGraph()\n",
    "\n",
    "# Add all nodes from G with their attributes\n",
    "for node, attrs in G.nodes(data=True):\n",
    "    node_only_graph.add_node(node, **attrs)\n",
    "\n",
    "# Load airports data and add them to the graph\n",
    "print('Loading airports data...')\n",
    "airports_path = os.path.join(PROJECT_ROOT, 'data', 'airac', 'airports.csv')\n",
    "if os.path.exists(airports_path):\n",
    "    airports_df = pd.read_csv(airports_path)\n",
    "    print(f'Adding {len(airports_df)} airports to the graph...')\n",
    "    \n",
    "    # Add airports as nodes to the graph\n",
    "    for _, airport in airports_df.iterrows():\n",
    "        if pd.notna(airport['icao']) and pd.notna(airport['latitude']) and pd.notna(airport['longitude']):\n",
    "            node_only_graph.add_node(\n",
    "                airport['icao'],\n",
    "                lat=airport['latitude'],\n",
    "                lon=airport['longitude'],\n",
    "                name=airport['name'] if pd.notna(airport['name']) else \"\",\n",
    "                elevation=airport['elevation'] if pd.notna(airport['elevation']) else 0,\n",
    "                type=\"airport\"\n",
    "            )\n",
    "else:\n",
    "    print('Airports data file not found.')\n",
    "\n",
    "print(f'Node-only graph created in {time.time() - start_time:.2f} seconds')\n",
    "print(f'Number of nodes: {node_only_graph.number_of_nodes()}')\n",
    "print(f'Number of edges: {node_only_graph.number_of_edges()}')\n",
    "\n",
    "# Save the node-only graph\n",
    "node_graph_path = os.path.join(PROJECT_ROOT, 'data', 'graphs', 'ats_fra_nodes_only.gml')\n",
    "nx.write_gml(node_only_graph, node_graph_path)\n",
    "print(f\"Node-only graph saved to {node_graph_path}\")\n",
    "print(f\"Node-only graph size: {os.path.getsize(node_graph_path) / 1024 / 1024:.2f} MB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the predecessor and successor into the graph\n",
    "\n",
    "To amortize the navigation cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise Exception('Do not proceed further! There are too many edges to be processed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, os\n",
    "time_start = time.time()\n",
    "print('Reading navigation graph...')\n",
    "import pickle\n",
    "G = pickle.load(open(os.path.join(PROJECT_ROOT, 'data', 'graphs', 'ats_fra_graph.pkl'), 'rb'))\n",
    "print(f'Navigation graph loaded in {time.time() - time_start:.2f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_edges = len(G.edges())\n",
    "edges = list(G.edges())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single threaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "# Precompute edge successors and predecessors\n",
    "edge_successors = {}\n",
    "edge_predecessors = {j: [] for j in range(num_edges)}\n",
    "\n",
    "# First create an adjacency mapping from nodes to edge indices\n",
    "node_to_outgoing_edges = {}\n",
    "for k, (u, v) in tqdm(enumerate(edges), total=num_edges, desc='Building edge successors and predecessors'):\n",
    "    if v not in node_to_outgoing_edges:\n",
    "        node_to_outgoing_edges[v] = []\n",
    "    if u not in node_to_outgoing_edges:\n",
    "        node_to_outgoing_edges[u] = []\n",
    "    node_to_outgoing_edges[v].append(k)\n",
    "\n",
    "# Now build the edge successors and predecessors in O(E) time\n",
    "for k, (u, v) in tqdm(enumerate(edges), total=num_edges, desc='Building edge successors and predecessors'):\n",
    "    # Include self (staying on same edge)\n",
    "    successors = [k]\n",
    "    # Add all edges starting with v\n",
    "    if v in node_to_outgoing_edges:\n",
    "        for j in node_to_outgoing_edges[v]:\n",
    "            if j != k:  # Avoid adding self twice\n",
    "                successors.append(j)\n",
    "                edge_predecessors[j].append(k)\n",
    "    \n",
    "    # Add self as predecessor (staying on same edge)\n",
    "    edge_predecessors[k].append(k)\n",
    "    edge_successors[k] = successors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi-threaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the edge successors and predecessors\n",
    "pickle.dump((edge_successors, edge_predecessors), open(os.path.join(PROJECT_ROOT, 'data', 'graphs', 'ats_fra_pred_succ.pkl'), 'wb'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mayflower",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
