{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "PROJECT_ROOT = os.getenv('PROJECT_ROOT')\n",
    "\n",
    "# Add PROJECT_ROOT to the Python path\n",
    "import sys\n",
    "sys.path.append(PROJECT_ROOT)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Origin: EGLL - HEATHROW (51.4775, -0.461389, 09R)\n",
      "Destination: UKBB - BORYSPIL INTL (50.344722, 30.893333, 18R)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ORIGIN_ICAO = 'EGLL'\n",
    "DEST_ICAO = 'UKBB'\n",
    "ORIGIN_RWY = '09R'\n",
    "DEST_RWY = '18R'\n",
    "\n",
    "airports_df = pd.read_csv(os.path.join(PROJECT_ROOT, \"data\", \"airac\", \"airports.csv\"))\n",
    "\n",
    "\n",
    "# Get the latitude and longitude of the origin and destination\n",
    "origin_lat = airports_df[airports_df['icao'] == ORIGIN_ICAO]['latitude'].values[0]\n",
    "origin_lon = airports_df[airports_df['icao'] == ORIGIN_ICAO]['longitude'].values[0]\n",
    "dest_lat = airports_df[airports_df['icao'] == DEST_ICAO]['latitude'].values[0]\n",
    "dest_lon = airports_df[airports_df['icao'] == DEST_ICAO]['longitude'].values[0]\n",
    "# Origin and destination airport names\n",
    "origin_name = airports_df[airports_df['icao'] == ORIGIN_ICAO]['name'].values[0]\n",
    "dest_name = airports_df[airports_df['icao'] == DEST_ICAO]['name'].values[0]\n",
    "\n",
    "print(f'Origin: {ORIGIN_ICAO} - {origin_name} ({origin_lat}, {origin_lon}, {ORIGIN_RWY})')\n",
    "print(f'Destination: {DEST_ICAO} - {dest_name} ({dest_lat}, {dest_lon}, {DEST_RWY})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subsetting the ATS graph to the great circle path between origin and destination...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding nodes to subset: 100%|██████████| 9558/9558 [00:00<00:00, 439342.86it/s]\n",
      "Adding edges to subset: 100%|██████████| 25011/25011 [00:00<00:00, 1885672.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATS graph loaded. Nodes: 1670, edges: 3817\n",
      "Building FRA routing options...\n",
      "Found 1037 FRA points within 100nm of the great circle path between origin and destination.          \n",
      "Merging these into the ATS graph...\n",
      "223 FRA points renamed for BALTIC & FRAIT & SECSI & SEE FRA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BALTIC & FRAIT & SECSI & SEE FRA: 100%|██████████| 267/267 [00:00<00:00, 1448.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35 FRA points renamed for BELFRA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BELFRA: 100%|██████████| 39/39 [00:00<00:00, 14003.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90 FRA points renamed for BOREALIS FRA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BOREALIS FRA: 100%|██████████| 202/202 [00:00<00:00, 3101.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 FRA points renamed for EDMM EAST\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EDMM EAST: 100%|██████████| 35/35 [00:00<00:00, 16509.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 FRA points renamed for EDUU EAST\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EDUU EAST: 100%|██████████| 49/49 [00:00<00:00, 17800.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53 FRA points renamed for EDUU NORTH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EDUU NORTH: 100%|██████████| 72/72 [00:00<00:00, 10132.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 FRA points renamed for EDUU WEST\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EDUU WEST: 100%|██████████| 16/16 [00:00<00:00, 41682.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 FRA points renamed for EDWW EAST\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EDWW EAST: 100%|██████████| 30/30 [00:00<00:00, 1217.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 FRA points renamed for LFFRANW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LFFRANW: 100%|██████████| 8/8 [00:00<00:00, 55461.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 FRA points renamed for MUAC FRA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MUAC FRA: 100%|██████████| 186/186 [00:00<00:00, 2248.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127 FRA points renamed for UKNESFRA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UKNESFRA: 100%|██████████| 133/133 [00:00<00:00, 2253.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FRA graph merged into ATS graph. Nodes: 2667, edges: 121054\n",
      "Computing cost for the ATS-FRA route graph...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding nodes to subset: 100%|██████████| 2667/2667 [00:00<00:00, 756131.46it/s]\n",
      "Adding edges to subset: 100%|██████████| 121054/121054 [00:00<00:00, 814579.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding SID and STAR graphs to the subset...\n",
      "Route graph subset created. Nodes: 2923, edges: 121334\n",
      "Great circle distance between origin and destination: 1179.84 nm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing predecessors list: 100%|██████████| 2923/2923 [00:00<00:00, 390581.11it/s]\n"
     ]
    }
   ],
   "source": [
    "from nav_graph import generate_navigraph, add_predecessor_access_for_graph\n",
    "\n",
    "route_graph = generate_navigraph(ORIGIN_ICAO, DEST_ICAO, origin_lat, origin_lon, dest_lat, dest_lon,\n",
    "                                  ORIGIN_RWY, DEST_RWY,\n",
    "                                  w_dct=1.0, w_fra=1.0, w_proc=0.2)\n",
    "add_predecessor_access_for_graph(route_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Origin node EGLL_09R not found in graph. Available nodes for EGLL:\n",
      "  EGLL\n",
      "Using EGLL as origin node instead\n",
      "Destination node UKBB_18R not found in graph. Available nodes for UKBB:\n",
      "  UKBB\n",
      "Using UKBB as destination node instead\n",
      "Shortest path found with 26 waypoints\n",
      "EGLL CPT5J WOD BPK Q295 BRAIN M197 REDFA DERAM L980 POLON M70 OKROT SLV SLV2J UKBB\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "from utils.flightplans import format_flightplan, get_detailed_flightplan_from_waypoint_list\n",
    "from utils.haversine import haversine_distance\n",
    "\n",
    "# Find the shortest path between origin and destination\n",
    "origin_node = f\"{ORIGIN_ICAO}_{ORIGIN_RWY}\"\n",
    "dest_node = f\"{DEST_ICAO}_{DEST_RWY}\"\n",
    "\n",
    "# Check if the nodes exist in the graph\n",
    "if origin_node not in route_graph.nodes:\n",
    "    print(f\"Origin node {origin_node} not found in graph. Available nodes for {ORIGIN_ICAO}:\")\n",
    "    for node in route_graph.nodes:\n",
    "        if node.startswith(ORIGIN_ICAO):\n",
    "            print(f\"  {node}\")\n",
    "    # Try to find an alternative\n",
    "    for node in route_graph.nodes:\n",
    "        if node.startswith(ORIGIN_ICAO):\n",
    "            origin_node = node\n",
    "            print(f\"Using {origin_node} as origin node instead\")\n",
    "            break\n",
    "\n",
    "if dest_node not in route_graph.nodes:\n",
    "    print(f\"Destination node {dest_node} not found in graph. Available nodes for {DEST_ICAO}:\")\n",
    "    for node in route_graph.nodes:\n",
    "        if node.startswith(DEST_ICAO):\n",
    "            print(f\"  {node}\")\n",
    "    # Try to find an alternative\n",
    "    for node in route_graph.nodes:\n",
    "        if node.startswith(DEST_ICAO):\n",
    "            dest_node = node\n",
    "            print(f\"Using {dest_node} as destination node instead\")\n",
    "            break\n",
    "\n",
    "# Find the shortest path\n",
    "try:\n",
    "    shortest_path = nx.shortest_path(route_graph, source=origin_node, target=dest_node, weight='cost')\n",
    "    print(f\"Shortest path found with {len(shortest_path)} waypoints\")\n",
    "    \n",
    "    \n",
    "    result = get_detailed_flightplan_from_waypoint_list(route_graph, shortest_path)\n",
    "\n",
    "    # Print the flight plan\n",
    "    print(format_flightplan(result))\n",
    "\n",
    "except nx.NetworkXNoPath:\n",
    "    print(f\"No path found between {origin_node} and {dest_node}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error finding path: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EGLL CPT5J_D130B CPT5J_D253K CPT5J_WOD WOD BPK TOTRI MATCH BRAIN GASBA RATLO REDFA ISMEF HLZ ARSAP DERAM POLON SOMOX TOLPA OKROT SLV SLV2J_SLV SLV2J_SL32B SLV2J_SLV50 SLV2J_D266B UKBB\n"
     ]
    }
   ],
   "source": [
    "print(\" \".join(shortest_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCMC Sampling with Metropolis-Hastings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from planner_pivot import mcmc_step\n",
    "MAX_ITER = 100\n",
    "BURN_IN = 5_000 # can go as high as 10_000\n",
    "THINNING = 25 # can go as high as 50 \n",
    "sampled_routes = []\n",
    "temperature = 10\n",
    "\n",
    "total_accepted = 0\n",
    "\n",
    "route = shortest_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "start_time = time.time()\n",
    "for i in range(MAX_ITER):\n",
    "    new_route, accepted = mcmc_step(route_graph, route, temperature, verbose = False,\n",
    "                                    max_depth=8)\n",
    "    \n",
    "    print(f'{i < BURN_IN and \"Burn-in\" or \"Sampling\"} | Iteration {i+1}, accepted: {total_accepted}               ', end='\\r')\n",
    "\n",
    "    if i < BURN_IN:\n",
    "        continue\n",
    "    \n",
    "    if accepted:\n",
    "        route = new_route\n",
    "        total_accepted += 1\n",
    "        \n",
    "    if i % THINNING == 0:\n",
    "        sampled_routes.append(route)\n",
    "        \n",
    "print(f\"Total chain time: {time.time() - start_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splicer Library MCMC Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add splicer library to the path\n",
    "import sys\n",
    "sys.path.append(os.path.join(PROJECT_ROOT, \"lateral\", \"splicer\"))\n",
    "import splicer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "def networkx_to_splicer(nx_graph):\n",
    "    \"\"\"\n",
    "    Convert a networkx graph with string waypoint names into a splicer Graph \n",
    "    (using integer IDs). Assumes each node has 'lat' and 'lon' attributes.\n",
    "    \n",
    "    Parameters:\n",
    "      nx_graph (networkx.Graph): A NetworkX graph with nodes as strings and \n",
    "                                 attributes 'lat' and 'lon'. Edge distances are\n",
    "                                 taken from the 'weight' attribute, or default to 1.0.\n",
    "    \n",
    "    Returns:\n",
    "      splicer_graph (planner.Graph): A splicer graph with integer-based node IDs.\n",
    "      name_to_id (dict): Mapping from the original string waypoint names to integer IDs.\n",
    "    \"\"\"\n",
    "    splicer_graph = splicer.Graph()\n",
    "    name_to_id = {}\n",
    "    \n",
    "    # Assign an integer ID for each node in the networkx graph.\n",
    "    for idx, node in enumerate(nx_graph.nodes()):\n",
    "        name_to_id[node] = idx\n",
    "        # Retrieve coordinates from node attributes; default to (0.0, 0.0) if not provided.\n",
    "        node_attrs = nx_graph.nodes[node]\n",
    "        lat = node_attrs.get(\"lat\", 0.0)\n",
    "        lon = node_attrs.get(\"lon\", 0.0)\n",
    "        splicer_graph.add_node(idx, lat, lon)\n",
    "    \n",
    "    # Add edges to the splicer graph using the new integer IDs.\n",
    "    for u, v, data in nx_graph.edges(data=True):\n",
    "        # Use the 'weight' attribute for the distance if available; default to 1.0.\n",
    "        distance = data.get(\"weight\", 1.0)\n",
    "        splicer_graph.add_edge(name_to_id[u], name_to_id[v], distance)\n",
    "    \n",
    "    return splicer_graph, name_to_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping from waypoint name to integer ID:\n",
      "  AMEPU -> 0\n",
      "  ROS -> 1\n",
      "  KL -> 2\n",
      "  BAKAM -> 3\n",
      "  NEPUT -> 4\n",
      "Initial route (integer IDs): [2667, 2670, 2671, 2672, 323, 122, 1223, 1086, 650, 640, 651, 381, 2431, 528, 1534, 538, 539, 693, 694, 695, 696, 2869, 2870, 2871, 2872, 2668]\n"
     ]
    }
   ],
   "source": [
    "# Convert the networkx graph to a splicer graph.\n",
    "splicer_graph, name_to_id = networkx_to_splicer(route_graph)\n",
    "\n",
    "print(\"Mapping from waypoint name to integer ID:\")\n",
    "for name, node_id in list(name_to_id.items())[:5]:\n",
    "    print(f\"  {name} -> {node_id}\")\n",
    "\n",
    "# Now you can use `splicer_graph` with the MCMC functions.\n",
    "# For example, create an initial route using integer IDs:\n",
    "initial_route = [name_to_id[name] for name in shortest_path]\n",
    "print(\"Initial route (integer IDs):\", initial_route)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_routes, final_route, total_accepted, acceptance_rate = splicer.start_mcmc(\n",
    "    splicer_graph,\n",
    "    initial_route,\n",
    "    temperature=10.0,\n",
    "    max_iter=MAX_ITER,\n",
    "    burn_in=BURN_IN,\n",
    "    thinning=THINNING,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a reverse mapping from ID to waypoint name\n",
    "id_to_name = {node_id: name for name, node_id in name_to_id.items()}\n",
    "\n",
    "# Convert the sampled routes back to waypoint names\n",
    "sampled_routes_names = []\n",
    "for route in sampled_routes:\n",
    "    route_names = [id_to_name[node_id] for node_id in route]\n",
    "    sampled_routes_names.append(route_names)\n",
    "\n",
    "# Print the first few sampled routes with waypoint names\n",
    "print(\"\\nSample of routes (waypoint names):\")\n",
    "for i, route in enumerate(sampled_routes_names[:3]):\n",
    "    print(f\"Route {i+1}: {route}\")\n",
    "    \n",
    "# Convert sampled routes to detailed flight plans\n",
    "print(\"\\nConverting sampled routes to detailed flight plans...\")\n",
    "\n",
    "detailed_flightplans = []\n",
    "for i, route in enumerate(sampled_routes_names):\n",
    "    try:\n",
    "        # Get detailed flight plan from waypoint list\n",
    "        detailed_plan = get_detailed_flightplan_from_waypoint_list(route_graph, route)\n",
    "        # Format the flight plan\n",
    "        formatted_plan = format_flightplan(detailed_plan)\n",
    "        detailed_flightplans.append(formatted_plan)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing route {i+1}: {e}\")\n",
    "\n",
    "# Print a few example flight plans\n",
    "print(\"\\nSample of formatted flight plans:\")\n",
    "for i, plan in enumerate(detailed_flightplans[:3]):\n",
    "    print(f\"\\nFlight Plan {i+1}:\")\n",
    "    print(plan)\n",
    "\n",
    "\n",
    "# Print statistics\n",
    "print(f\"\\nTotal routes sampled: {len(sampled_routes)}\")\n",
    "print(f\"Acceptance rate: {acceptance_rate:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histogram and Frequency Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a histogram of flight plan frequencies\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Count the frequency of each flight plan\n",
    "flightplan_counter = Counter(detailed_flightplans)\n",
    "\n",
    "# Get the top 20 most common flight plans\n",
    "most_common = flightplan_counter.most_common(20)\n",
    "\n",
    "# Extract data for plotting\n",
    "plans = [f\"Plan {i+1}\" for i in range(len(most_common))]\n",
    "frequencies = [count for _, count in most_common]\n",
    "\n",
    "# Create the histogram\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(plans, frequencies)\n",
    "plt.xlabel('Flight Plans')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Frequency of Top 20 Flight Plans')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Print the most common flight plans with their frequencies\n",
    "print(\"Top 5 most common flight plans:\")\n",
    "for i, (plan, count) in enumerate(most_common[:5]):\n",
    "    print(f\"\\nPlan {i+1} (percentage: {count/len(detailed_flightplans)*100:.2f}%):\")\n",
    "    print(plan)\n",
    "\n",
    "# Calculate and print some statistics\n",
    "total_unique_plans = len(flightplan_counter)\n",
    "print(f\"\\nTotal unique flight plans: {total_unique_plans}\")\n",
    "print(f\"Most common flight plan appears {most_common[0][1]} times\")\n",
    "print(f\"Percentage of flights using the most common plan: {most_common[0][1]/len(detailed_flightplans)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
